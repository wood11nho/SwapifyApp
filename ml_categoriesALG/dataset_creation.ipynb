{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pyunsplash import PyUnsplash\n",
    "from config import UNSPLASH_API\n",
    "\n",
    "access_key = UNSPLASH_API['access_key']\n",
    "\n",
    "py_unsplash = PyUnsplash(api_key=access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-nbKdLAZ31A\n",
      "zngv0qaBW0E\n",
      "z99mHCXDLjE\n",
      "8GzbKs74yq4\n",
      "hNP1i6BTizU\n",
      "GpQzF1AjVN0\n",
      "QBBAojjhqEc\n",
      "Jlt58eKwq6k\n",
      "zOYzFNLZIKc\n",
      "QaQGrLDRSFQ\n",
      "JavdKoyGF28\n",
      "88bjhdVWgWM\n",
      "vvzllGGRX6A\n",
      "ARqzUe8ez_4\n",
      "dVahTuF8Y_o\n",
      "Tz3G6xo0JYg\n",
      "Pu8nlle8Lhk\n",
      "D6OyQjq_66o\n",
      "PPCxeroNsPA\n",
      "XONWuXYVVAQ\n",
      "yhZ5muJv108\n",
      "H5yHkT6JttE\n",
      "MJdULYQRd_g\n",
      "yntJplAGPfM\n",
      "g3u3bRzlaTY\n",
      "XdHhhrCgdWA\n",
      "wbAYAKI_jsY\n",
      "QDeCkIABn6o\n",
      "pOwLntU-CVg\n",
      "9i95BQ0-jos\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Get the biggest number of photos that is available\n",
    "shoes_images_search = py_unsplash.search(type_='photos', query='shoes', page=100, per_page=100)\n",
    "\n",
    "for shoes_photo in shoes_images_search.entries:\n",
    "    # Save the photo to the local folder\n",
    "    response = requests.get(shoes_photo.link_download, allow_redirects=True)\n",
    "    open('shoes_photos/' + shoes_photo.id + '.jpg', 'wb').write(response.content)\n",
    "    print(shoes_photo.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. FOOTBALL KITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = open('football_kits.csv', 'r')\n",
    "csv_reader = csv.reader(csv_file)\n",
    "\n",
    "category = 'Retro kits'\n",
    "category_folder = f'dataset/{category}'\n",
    "\n",
    "for i, row in enumerate(csv_reader):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    img_url = row[2] # kit photo url\n",
    "    img_data = requests.get(img_url).content\n",
    "    if not os.path.exists(category_folder):\n",
    "        os.makedirs(category_folder)\n",
    "    with open(f'{category_folder}/{category}_{i}.jpg', 'wb') as f:\n",
    "        f.write(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. SHOES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all images from archive/test and archive/train and put them in dataset/Shoes as Shoes_1.jpg, Shoes_2.jpg, etc.\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "adidas_test_dir = 'archive/test/adidas'\n",
    "converse_test_dir = 'archive/test/converse'\n",
    "nike_test_dir = 'archive/test/nike'\n",
    "adidas_train_dir = 'archive/train/adidas'\n",
    "converse_train_dir = 'archive/train/converse'\n",
    "nike_train_dir = 'archive/train/nike'\n",
    "shoes_dir = 'dataset/Shoes'\n",
    "current_index = 1\n",
    "\n",
    "if not os.path.exists(shoes_dir):\n",
    "    os.makedirs(shoes_dir)\n",
    "\n",
    "def copy_files(source_dir, dest_dir, current_index=current_index):\n",
    "    for file in os.listdir(source_dir):\n",
    "        shutil.copyfile(os.path.join(source_dir, file), os.path.join(dest_dir, f'Shoes_{current_index}.jpg'))\n",
    "        current_index += 1\n",
    "    return current_index\n",
    "\n",
    "current_index = copy_files(adidas_test_dir, shoes_dir, current_index)\n",
    "current_index = copy_files(converse_test_dir, shoes_dir, current_index)\n",
    "current_index = copy_files(nike_test_dir, shoes_dir, current_index)\n",
    "current_index = copy_files(adidas_train_dir, shoes_dir, current_index)\n",
    "current_index = copy_files(converse_train_dir, shoes_dir, current_index)\n",
    "current_index = copy_files(nike_train_dir, shoes_dir, current_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. TRADING CARDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://images.ygoprodeck.com/images/cards/34541863.jpg\n"
     ]
    }
   ],
   "source": [
    "trading_cards_csv = pd.read_csv('trading_cards.csv')\n",
    "trading_cards_str = trading_cards_csv['card_images'][0]\n",
    "trading_cards_list = ast.literal_eval(trading_cards_str)\n",
    "\n",
    "image_url = trading_cards_list[0]['image_url']\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_cards_csv = pd.read_csv('trading_cards.csv')\n",
    "trading_cards_str = trading_cards_csv['card_images']\n",
    "\n",
    "index = 1\n",
    "trading_cards_dir = 'dataset/Trading cards'\n",
    "if not os.path.exists(trading_cards_dir):\n",
    "    os.makedirs(trading_cards_dir)\n",
    "\n",
    "for line in trading_cards_str:\n",
    "    trading_cards_list = ast.literal_eval(line)\n",
    "    image_url = trading_cards_list[0]['image_url']\n",
    "    image_data = requests.get(image_url).content\n",
    "    with open(f'{trading_cards_dir}/Trading_cards_{index}.jpg', 'wb') as f:\n",
    "        f.write(image_data)\n",
    "    index += 1\n",
    "\n",
    "    if index == 1000:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. BOOKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
