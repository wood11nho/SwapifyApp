{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import firestore\n",
    "\n",
    "# We should create a dictionary, and to have for exampel dict[userId] = [itemInteractions, postedItems, searchHistory], where\n",
    "# itemInteractions, postedItems, searchHistory are arrays of strings\n",
    "\n",
    "# Get all documents from USER_PREFERENCES collection\n",
    "db = firestore.Client(project='swapify-e426d')\n",
    "\n",
    "collection_name = 'USER_PREFERENCES'\n",
    "docs = db.collection(collection_name).stream()\n",
    "\n",
    "# Process Firestore data\n",
    "user_item_data = []\n",
    "for doc in docs:\n",
    "    user_id = doc.id\n",
    "    data = doc.to_dict()\n",
    "    items = set(data.get('itemInteractions', []) + data.get('postedItems', []) + data.get('searchHistory', []))\n",
    "    for item in items:\n",
    "        user_item_data.append([user_id, item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['gxRY52w1CMhuzG8fwkPNuiO1FER2', 'Retro kits'], ['gxRY52w1CMhuzG8fwkPNuiO1FER2', 'Tricou Liverpool Torres'], ['gxRY52w1CMhuzG8fwkPNuiO1FER2', 'Funko Pops and Figures'], ['gxRY52w1CMhuzG8fwkPNuiO1FER2', 'Vand Tricou cu FC Liverpool, Fernando Torres 9, Marimea M, Livrare prin curier sau meet up in Bucuresti'], ['gxRY52w1CMhuzG8fwkPNuiO1FER2', 'Buna! Vreau sa fac trade cu alte Funko pentru ce vedeti in imagine. PM '], ['gxRY52w1CMhuzG8fwkPNuiO1FER2', 'tricouri fotbal\\n'], ['gxRY52w1CMhuzG8fwkPNuiO1FER2', 'Shoes'], ['gxRY52w1CMhuzG8fwkPNuiO1FER2', 'Vand pantofi Nike, Marimea 39, Astept mesaje in privat. Nu trimit pe curier']]\n"
     ]
    }
   ],
   "source": [
    "# Print data\n",
    "print(user_item_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item     0  1  2  3  4  5  6  7\n",
      "user_id                        \n",
      "0        1  1  1  1  1  1  1  1\n"
     ]
    }
   ],
   "source": [
    "# Convert to dataframe\n",
    "df = pd.DataFrame(user_item_data, columns=['user_id', 'item'])\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "df['user_id'] = user_encoder.fit_transform(df['user_id'])\n",
    "df['item'] = item_encoder.fit_transform(df['item'])\n",
    "\n",
    "interaction_matrix = df.pivot_table(index='user_id', columns='item', aggfunc=len, fill_value=0)\n",
    "print(interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "sparse_interaction_matrix = csr_matrix(interaction_matrix.values)\n",
    "print(sparse_interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item       0    1    2    3    4    5    6    7\n",
      "user_id                                        \n",
      "0        1.0  2.0  4.0  1.0  1.0  3.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "collection_name = 'USER_PREFERENCES'\n",
    "docs = db.collection(collection_name).stream()\n",
    "\n",
    "user_item_counter = Counter()\n",
    "\n",
    "for doc in docs:\n",
    "    user_id = doc.id\n",
    "    data = doc.to_dict()\n",
    "    items = data.get('itemInteractions', []) + data.get('postedItems', []) + data.get('searchHistory', [])\n",
    "    for item in items:\n",
    "        user_item_counter[(user_id, item)] += 1\n",
    "\n",
    "user_item_data_with_count = [[user_id, item, count] for (user_id, item), count in user_item_counter.items()]\n",
    "df_with_count = pd.DataFrame(user_item_data_with_count, columns=['user_id', 'item', 'count'])\n",
    "\n",
    "df_with_count['user_id'] = user_encoder.fit_transform(df_with_count['user_id'])\n",
    "df_with_count['item'] = item_encoder.fit_transform(df_with_count['item'])\n",
    "\n",
    "interaction_matrix_with_count = df_with_count.pivot_table(index='user_id', columns='item', values='count', fill_value=0)\n",
    "print(interaction_matrix_with_count)\n",
    "\n",
    "sparse_interaction_matrix_with_count = csr_matrix(interaction_matrix_with_count.values)\n",
    "# print(sparse_interaction_matrix_with_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(uid=0, iid=2, r_ui=4.0, est=1.5076692496020259, details={'was_impossible': False}), Prediction(uid=0, iid=6, r_ui=1.0, est=1.5076692496020259, details={'was_impossible': False})]\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Convert the dataset into the specific format that Surprise uses\n",
    "coo = coo_matrix(sparse_interaction_matrix_with_count)\n",
    "df_for_surprise = pd.DataFrame({'user_id': coo.row, 'item': coo.col, 'rating': coo.data})\n",
    "df_for_surprise = df_for_surprise[df_for_surprise['rating'] > 0]\n",
    "\n",
    "# Load the dataset into Surprise\n",
    "reader = Reader(rating_scale=(1, df_for_surprise['rating'].max()))\n",
    "data = Dataset.load_from_df(df_for_surprise[['user_id', 'item', 'rating']], reader)\n",
    "\n",
    "# Split the dataset into train and test\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Train the model\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Predict the rating for a specific user and item\n",
    "predictions = algo.test(testset)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.7985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.798532823772034"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_item_interactions = list(set([item for _, item in user_item_data]))\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_model = tfidf.fit(all_item_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_string(item_id):\n",
    "    return item_encoder.inverse_transform([item_id])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([0.03665369, 0.0347655 , 0.06496356, 0.03665369, 0.03409701,\n",
      "       0.0347655 , 0.0347655 , 0.05771216, 0.05929461, 0.0347655 ,\n",
      "       0.03409701, 0.03409701, 0.06496356, 0.08838835, 0.08358073,\n",
      "       0.0347655 , 0.07630853, 0.08838835, 0.10074474, 0.03409701,\n",
      "       0.05929461, 0.03409701, 0.03665369, 0.03665369, 0.03665369,\n",
      "       0.03665369, 0.03665369, 0.0347655 , 0.0347655 , 0.06496356,\n",
      "       0.03409701, 0.03665369, 0.08838835, 0.0347655 , 0.03409701,\n",
      "       0.125     , 0.10074474, 0.0347655 , 0.10074474, 0.08838835,\n",
      "       0.03665369, 0.03409701, 0.05929461, 0.0347655 , 0.0347655 ])}\n"
     ]
    }
   ],
   "source": [
    "user_profiles = {}\n",
    "\n",
    "for user_id in set(df['user_id']):\n",
    "    user_items_ids = df[df['user_id'] == user_id]['item']\n",
    "    user_items_strings = [get_item_string(item_id) for item_id in user_items_ids]\n",
    "    user_items_tfidf = tfidf_model.transform(user_items_strings)\n",
    "    user_profiles[user_id] = np.mean(user_items_tfidf, axis=0).A1\n",
    "\n",
    "print(user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_item_name = \"Tricou Fotbal Ronaldo\"\n",
    "new_item_category = \"Retro kits\"\n",
    "new_item_description = \"Tricou Fotbal Ronaldo Real Madrid sezonul 2018-2019, marimea L, culoare albastru, trimit si in tara\"\n",
    "\n",
    "new_item_text = new_item_name + \" \" + new_item_category + \" \" + new_item_description\n",
    "new_item_vector = tfidf.transform([new_item_text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5137456526032076}\n"
     ]
    }
   ],
   "source": [
    "user_interest_predictions = {}\n",
    "\n",
    "for user_id, profile in user_profiles.items():\n",
    "    similarity = cosine_similarity([profile], new_item_vector)\n",
    "    user_interest_predictions[user_id] = similarity[0][0]\n",
    "\n",
    "print(user_interest_predictions)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
